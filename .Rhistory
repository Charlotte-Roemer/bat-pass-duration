Correlation_list2 = c(Correlation_list2, Correlation_list_temp2)
}
a
ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
title(Sp) +
viridis::scale_fill_viridis(name = name_diff,
option = "A",
na.value = alpha("lightgrey", 0))
ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp) +
viridis::scale_fill_viridis(name = name_diff,
option = "A",
na.value = alpha("lightgrey", 0))
ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
width = 10, height = 8, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
width = 1000, height = 1000, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
width = 100, height = 100, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
width = 10, height = 10, dpi=300)
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
unix = "px", width = 10, height = 8, dpi=300)
}
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
unix = "px", width = 1000, height = 800, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
units = "px", width = 1000, height = 800, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
units = "px", width = 1500, height = 1200, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
units = "px", width = 2000, height = 1700, dpi=300)
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
units = "px", width = 2000, height = 1800, dpi=300)
}
Month_i
paste0(Month_i, " ", Day_name)
paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png")
DateModel="2023-11-17" #date of prediction (exactly same writing as the folder name)
paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png")
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1800, dpi=300)
}
# For each species
Correlation_list2 = list()
for (i in 1: length(ListSpdata) ) {
Sp = ListSpdata[i]
print(Sp)
# For each month
Correlation_list = list()
for (j in 1: length(ListMonthdata) ) {
# For each day
for (k in 1:2){
Month_i = ListMonthdata[j]
Day_name <- ifelse(k==1, "01", "15")
print(paste0(Month_i, " ", Day_name))
# Calculate correlations
f = function(x) {
log10(x+2) # to normalise variables to allow using pearson's correlation coefficient
}
dataCOR = file_bind %>% # prepare table
dplyr::select(!err) %>%
filter (Species == Sp & Month == Month_i, Day == Day_name) %>%
pivot_wider(names_from = Threshold, values_from = pred)
if(nrow(dataCOR)>0 & ncol(dataCOR)>8){
dataCOR2 = dataCOR %>%
mutate_at(vars(matches(c("0", "50", "90", "weighted"))), list(normal = f)) # normalise
# Correlation matrix
M<-cor(dataCOR2[,c("0_normal",  "50_normal",  "90_normal", "weighted_normal")])
#OVERlap = olaps(dataCOR2$'0_normal', dataCOR2$'50_normal',
#                dataCOR2$'90_normal', dataCOR2$'weighted_normal')
# Store in list
#Correlation_list_temp = list(OVERlap)
Correlation_list_temp = list(M)
names(Correlation_list_temp) = paste0(Sp, " ", Month_i, " ", Day_name)
Correlation_list = c(Correlation_list, Correlation_list_temp)
# Plot difference map
val0 = '0_normal'
val50 = '50_normal'
val90 = '90_normal'
valW = 'weighted_normal'
dataa_diff_0_50 = Raster_difference(dataCOR2, val0, val50)
dataa_diff_0_90 = Raster_difference(dataCOR2, val0, val90)
dataa_diff_0_Weighted = Raster_difference(dataCOR2, val0, valW)
dataa_diff_50_90 = Raster_difference(dataCOR2, val50, val90)
dataa_diff_50_Weighted = Raster_difference(dataCOR2, val50, valW)
dataa_diff_90_Weighted = Raster_difference(dataCOR2, val90, valW)
list_diff = list(dataa_diff_0_50, dataa_diff_0_90, dataa_diff_0_Weighted,
dataa_diff_50_90, dataa_diff_50_Weighted, dataa_diff_90_Weighted)
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1800, dpi=300)
}
}
}
}
# Calculate mean value of each correlation accross all dates
Correlation_mean = Reduce(`+`, Correlation_list) / length(Correlation_list)
Correlation_list_temp2 = list(Correlation_mean)
names(Correlation_list_temp2) = paste0(Sp)
Correlation_list2 = c(Correlation_list2, Correlation_list_temp2)
}
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 2000, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 1800, height = 2000, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1600, dpi=300)
# For each species
Correlation_list2 = list()
for (i in 1: length(ListSpdata) ) {
Sp = ListSpdata[i]
print(Sp)
# For each month
Correlation_list = list()
for (j in 1: length(ListMonthdata) ) {
# For each day
for (k in 1:2){
Month_i = ListMonthdata[j]
Day_name <- ifelse(k==1, "01", "15")
print(paste0(Month_i, " ", Day_name))
# Calculate correlations
f = function(x) {
log10(x+2) # to normalise variables to allow using pearson's correlation coefficient
}
dataCOR = file_bind %>% # prepare table
dplyr::select(!err) %>%
filter (Species == Sp & Month == Month_i, Day == Day_name) %>%
pivot_wider(names_from = Threshold, values_from = pred)
if(nrow(dataCOR)>0 & ncol(dataCOR)>8){
dataCOR2 = dataCOR %>%
mutate_at(vars(matches(c("0", "50", "90", "weighted"))), list(normal = f)) # normalise
# Correlation matrix
M<-cor(dataCOR2[,c("0_normal",  "50_normal",  "90_normal", "weighted_normal")])
#OVERlap = olaps(dataCOR2$'0_normal', dataCOR2$'50_normal',
#                dataCOR2$'90_normal', dataCOR2$'weighted_normal')
# Store in list
#Correlation_list_temp = list(OVERlap)
Correlation_list_temp = list(M)
names(Correlation_list_temp) = paste0(Sp, " ", Month_i, " ", Day_name)
Correlation_list = c(Correlation_list, Correlation_list_temp)
# Plot difference map
val0 = '0_normal'
val50 = '50_normal'
val90 = '90_normal'
valW = 'weighted_normal'
dataa_diff_0_50 = Raster_difference(dataCOR2, val0, val50)
dataa_diff_0_90 = Raster_difference(dataCOR2, val0, val90)
dataa_diff_0_Weighted = Raster_difference(dataCOR2, val0, valW)
dataa_diff_50_90 = Raster_difference(dataCOR2, val50, val90)
dataa_diff_50_Weighted = Raster_difference(dataCOR2, val50, valW)
dataa_diff_90_Weighted = Raster_difference(dataCOR2, val90, valW)
list_diff = list(dataa_diff_0_50, dataa_diff_0_90, dataa_diff_0_Weighted,
dataa_diff_50_90, dataa_diff_50_Weighted, dataa_diff_90_Weighted)
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1600, dpi=300)
}
}
}
}
# Calculate mean value of each correlation accross all dates
Correlation_mean = Reduce(`+`, Correlation_list) / length(Correlation_list)
Correlation_list_temp2 = list(Correlation_mean)
names(Correlation_list_temp2) = paste0(Sp)
Correlation_list2 = c(Correlation_list2, Correlation_list_temp2)
}
beep(2)
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
limits = c(-1,1),
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1600, dpi=300)
# For each species
Correlation_list2 = list()
for (i in 1: length(ListSpdata) ) {
Sp = ListSpdata[i]
print(Sp)
# For each month
Correlation_list = list()
for (j in 1: length(ListMonthdata) ) {
# For each day
for (k in 1:2){
Month_i = ListMonthdata[j]
Day_name <- ifelse(k==1, "01", "15")
print(paste0(Month_i, " ", Day_name))
# Calculate correlations
f = function(x) {
log10(x+2) # to normalise variables to allow using pearson's correlation coefficient
}
dataCOR = file_bind %>% # prepare table
dplyr::select(!err) %>%
filter (Species == Sp & Month == Month_i, Day == Day_name) %>%
pivot_wider(names_from = Threshold, values_from = pred)
if(nrow(dataCOR)>0 & ncol(dataCOR)>8){
dataCOR2 = dataCOR %>%
mutate_at(vars(matches(c("0", "50", "90", "weighted"))), list(normal = f)) # normalise
# Correlation matrix
M<-cor(dataCOR2[,c("0_normal",  "50_normal",  "90_normal", "weighted_normal")])
#OVERlap = olaps(dataCOR2$'0_normal', dataCOR2$'50_normal',
#                dataCOR2$'90_normal', dataCOR2$'weighted_normal')
# Store in list
#Correlation_list_temp = list(OVERlap)
Correlation_list_temp = list(M)
names(Correlation_list_temp) = paste0(Sp, " ", Month_i, " ", Day_name)
Correlation_list = c(Correlation_list, Correlation_list_temp)
# Plot difference map
val0 = '0_normal'
val50 = '50_normal'
val90 = '90_normal'
valW = 'weighted_normal'
dataa_diff_0_50 = Raster_difference(dataCOR2, val0, val50)
dataa_diff_0_90 = Raster_difference(dataCOR2, val0, val90)
dataa_diff_0_Weighted = Raster_difference(dataCOR2, val0, valW)
dataa_diff_50_90 = Raster_difference(dataCOR2, val50, val90)
dataa_diff_50_Weighted = Raster_difference(dataCOR2, val50, valW)
dataa_diff_90_Weighted = Raster_difference(dataCOR2, val90, valW)
list_diff = list(dataa_diff_0_50, dataa_diff_0_90, dataa_diff_0_Weighted,
dataa_diff_50_90, dataa_diff_50_Weighted, dataa_diff_90_Weighted)
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
limits = c(-1,1),
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1600, dpi=300)
}
}
}
}
# Calculate mean value of each correlation accross all dates
Correlation_mean = Reduce(`+`, Correlation_list) / length(Correlation_list)
Correlation_list_temp2 = list(Correlation_mean)
names(Correlation_list_temp2) = paste0(Sp)
Correlation_list2 = c(Correlation_list2, Correlation_list_temp2)
}
install.packages("pracma")
setwd("C:/Users/croemer01/Documents/R/bat-pass-duration")
arg="../example files/association_buzz_species_ID/" # directory with outputs script 0_Associate_species_ID_with_buzz.R
arg[2]= "../example files/nb_buzz_per_night/" # output directory
arg[3] = "../f2pPF.R" # f2pPF function
library(tidyverse)
library(gdata)
library(data.table)
# List files
part <- list.files(arg[1], full.names = T)
part
arg="../example files/association_buzz_species_ID" # directory with outputs script 0_Associate_species_ID_with_buzz.R
arg[2]= "../example files/nb_buzz_per_night/" # output directory
arg[3] = "../f2pPF.R" # f2pPF function
# List files
part <- list.files(arg[1], full.names = T)
part
arg="../example files/association_buzz_species_ID/" # directory with outputs script 0_Associate_species_ID_with_buzz.R
arg[2]= "../example files/nb_buzz_per_night/" # output directory
arg[3] = "../f2pPF.R" # f2pPF function
list.files(arg[1])
getwd()
# List files
part <- list.files(paste0("C:/Users/croemer01/Documents/R/bat-pass-duration", arg[1]), full.names = T)
part
paste0("C:/Users/croemer01/Documents/R/bat-pass-duration", arg[1])
# List files
list.files("C:/Users/croemer01/Documents/R/bat-pass-duration/example files/association_buzz_species_ID/", full.names = T)
# List files
list.files("C:/Users/croemer01/Documents/R/bat-pass-duration/example files/../association_buzz_species_ID/", full.names = T)
arg="./example files/association_buzz_species_ID/" # directory with outputs script 0_Associate_species_ID_with_buzz.R
arg[2]= "../example files/nb_buzz_per_night/" # output directory
arg[3] = "../f2pPF.R" # f2pPF function
list.files(arg[1])
hist(data_pippip$mean_dur)
library(tidyverse)
library(glmmTMB)
library(ggeffects)
data <- read_delim("./final_data_update.csv")
data <- read_delim("./example files/final_data_update.csv")
# Response variable
data$buzz_rate <- (data$nb_buzz/(data$duration_sum))*3600 # calculate number of buzzes per hour ; duration_sum = duration of cumulated bat passes
hist(data$buzz_rate)
head(data)
data <- read_delim("../final_data_update.csv")
# Response variable
data$buzz_rate <- (data$nb_buzz/(data$duration_sum))*3600 # calculate number of buzzes per hour ; duration_sum = duration of cumulated bat passes
data$buzz_rate <- as.integer(data$buzz_rate)
data <- read_delim("./example files/final_data_update.csv")
# Response variable
data$buzz_rate <- (data$nb_buzz/(data$duration_sum))*3600 # calculate number of buzzes per hour ; duration_sum = duration of cumulated bat passes
head(data)
data <- read_delim("../final_data_update.csv")
# Response variable
data$buzz_rate <- (data$nb_buzz/(data$duration_sum))*3600 # calculate number of buzzes per hour ; duration_sum = duration of cumulated bat passes
data$buzz_rate <- as.integer(data$buzz_rate)
hist(data$buzz_rate)
# Julian Day
data$jour_j <- yday(data$nuit)
hist(data$jour_j)
# Select common pipistrelle
data_pippip <- subset(data, data$esp=="pippip")
hist(data_pippip$mean_dur)
hist(data_pippip$st_deviation)
hist(log10(data_pippip$mean_dur))
hist(data_pippip$buzz_rate)
hist(log10(data_pippip$buzz_rate))
cor(log10(data_pippip$mean_dur), data_pippip$st_deviation, method = 'pearson')
cor.test(log10(data_pippip$mean_dur), data_pippip$st_deviation, method = 'pearson')
cor.test(log10(data_pippip$mean_dur), log10(data_pippip$st_deviation), method = 'pearson')
cor.test(log10(data_pippip$mean_dur), data_pippip$st_deviation, method = 'pearson')
cor.test(log10(data_pippip$buzz_rate), data_pippip$mean_dur, method = 'pearson')
cor.test(log10(data_pippip$buzz_rate), log10(data_pippip$mean_dur), method = 'pearson')
hist(log10(data_pippip$mean_dur))
hist(log10(data_pippip$buzz_rate))
summary(log10(data_pippip$buzz_rate))
cor.test(log10(data_pippip$buzz_rate+1), log10(data_pippip$mean_dur+1), method = 'pearson')
cor.test(log10(data_pippip$buzz_rate+1), data_pippip$st_deviation, method = 'pearson')
cor.test(log10(data_pippip$mean_dur+1), data_pippip$st_deviation, method = 'pearson')
cor.test(log10(data_pippip$mean_dur+1), log10(data_pippip$st_deviation+1), method = 'pearson')
cor.test(log10(data_pippip$mean_dur+1), data_pippip$st_deviation, method = 'pearson')
data <- read_delim("../final_data_update.csv")
# Response variable
data$buzz_rate <- (data$nb_buzz/(data$duration_sum))*3600 # calculate number of buzzes per hour ; duration_sum = duration of cumulated bat passes
data$buzz_rate <- as.integer(data$buzz_rate)
hist(data$buzz_rate)
# Select common pipistrelle
data_pippip <- subset(data, data$esp=="pippip")
m0_a <- glmmTMB(buzz_rate~ 1 + (1|localite), data = data_pippip, family = "poisson")
summary(m0_a)
m0_b <- glmmTMB(buzz_rate~ 1 + (1|localite), data = data_pippip, family = "nbinom2")
summary(m0_b)
m0_c <- glmmTMB(buzz_rate~ 1 + (1|localite), zi=~1, data = data_pippip, family = "nbinom2")
summary(m0_c)
m1_a <- glmmTMB(buzz_rate~mean_dur  + (1|localite), data = data_pippip, family = "poisson")
summary(m1_a)
m1_b <- glmmTMB(buzz_rate~mean_dur +  (1|localite), data = data_pippip, family = "nbinom2")
summary(m1_b)
m1_c <- glmmTMB(buzz_rate~mean_dur +  (1|localite), zi=~1, data = data_pippip, family = "nbinom2")
summary(m1_c)
m2_a <- glmmTMB(buzz_rate~st_deviation +  (1|localite), data = data_pippip, family = "poisson")
summary(m2_a)
m2_b <- glmmTMB(buzz_rate~st_deviation +  (1|localite), data = data_pippip, family = "nbinom2")
summary(m2_b)
m2_c <- glmmTMB(buzz_rate~st_deviation +  (1|localite), zi=~1, data = data_pippip, family = "nbinom2")
summary(m2_c)
m3_a <- glmmTMB(buzz_rate~mean_dur + st_deviation +  (1|localite), data = data_pippip, family = "poisson")
summary(m3_a)
m3_b <- glmmTMB(buzz_rate~mean_dur + st_deviation +  (1|localite), data = data_pippip, family = "nbinom2")
summary(m3_b)
m3_c <- glmmTMB(buzz_rate~mean_dur + st_deviation +  (1|localite), zi=~1, data = data_pippip, family = "nbinom2")
summary(m3_c)
AIC(m0_a, m0_b, m0_c, m1_a, m1_b, m1_c, m2_a, m2_b, m2_c, m3_a, m3_b, m3_c)
m1_a <- glmmTMB(buzz_rate~mean_dur  + (1|localite), data = data_pippip, family = "poisson")
m1_a <- glmmTMB(buzz_rate~log10(mean_dur)  + (1|localite), data = data_pippip, family = "poisson")
m1_a <- glmmTMB(buzz_rate~log10(mean_dur+1)  + (1|localite), data = data_pippip, family = "poisson")
summary(m1_a)
ggplot(pr1, aes(x, predicted)) +
geom_line(linewidth=1, col = "#003333")  +
geom_ribbon(aes(ymin = conf.low, ymax = conf.high), fill = "#003333", alpha = .1)+
labs(x = "Mean bat pass duration (s)",
y = "Number of \nfeeding buzzes/hour") +
scale_fill_discrete(guide=FALSE)+
scale_y_continuous(trans='log10') +
theme_bw(base_size = 15)+
geom_rug(data=data_pippip,aes(x=mean_dur, y=NULL),sides="b")
# Plot
pr1 = ggpredict(m1_c, "mean_dur")
setwd("C:/Users/croemer01/Documents/Publications/Bat pass duration")
png(filename=paste("Bat_pass_duration_buzz_rate.png",sep=""), height=1000, width=1500,res=300)
plot1=ggplot(pr1, aes(x, predicted)) +
geom_line(linewidth=1, col = "#003333")  +
geom_ribbon(aes(ymin = conf.low, ymax = conf.high), fill = "#003333", alpha = .1)+
labs(x = "Mean bat pass duration (s)",
y = "Number of \nfeeding buzzes/hour") +
scale_fill_discrete(guide=FALSE)+
scale_y_continuous(trans='log10') +
theme_bw(base_size = 15)+
geom_rug(data=data_pippip,aes(x=mean_dur, y=NULL),sides="b")
print(plot1)
dev.off()
library(DHARMa)
res_m1_c = simulateResiduals(m1_c)
plot(res_m1_c)
dim(data_pippip)
head(data_pippip)
m1_c <- glmmTMB(buzz_rate~log10(mean_dur) +  (1|localite), zi=~1, data = data_pippip, family = "nbinom2")
res_m1_c = simulateResiduals(m1_c)
plot(res_m1_c)
# Julian Day
data$jour_j <- yday(data$nuit)
hist(data$jour_j)
m1_c <- glmmTMB(buzz_rate~log10(mean_dur) + poly(jour_j, 2) (1|localite), zi=~1, data = data_pippip, family = "nbinom2")
# Select common pipistrelle
data_pippip <- subset(data, data$esp=="pippip")
m1_c <- glmmTMB(buzz_rate~log10(mean_dur) + poly(jour_j, 2) (1|localite), zi=~1, data = data_pippip, family = "nbinom2")
m1_c <- glmmTMB(buzz_rate~log10(mean_dur) + poly(jour_j, 2) + (1|localite), zi=~1, data = data_pippip, family = "nbinom2")
summary(m1_c)
res_m1_c = simulateResiduals(m1_c)
plot(res_m1_c)
m1_c <- glmmTMB(buzz_rate~mean_dur + (1|localite), zi=~1, data = data_pippip, family = "nbinom2")
res_m1_c = simulateResiduals(m3_c)
plot(res_m1_c)
m3_c <- glmmTMB(buzz_rate~log10(mean_dur+1) + st_deviation +  (1|localite), zi=~1, data = data_pippip, family = "nbinom2")
res_m1_c = simulateResiduals(m3_c)
plot(res_m1_c)
m1_c <- glmmTMB(buzz_rate~mean_dur + poly(jour_j,2) + (1|localite), zi=~1, data = data_pippip, family = "nbinom2")
res_m1_c = simulateResiduals(m1_c)
plot(res_m1_c)
head(data)
data <- read_delim("../final_data_update.csv") %>%
as.data.frame()
getwd()
