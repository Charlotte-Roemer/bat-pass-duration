Day_name <- ifelse(k==1, "01", "15")
print(paste0(Month_i, " ", Day_name))
# Calculate correlations
f = function(x) {
log10(x+2) # to normalise variables to allow using pearson's correlation coefficient
}
dataCOR = file_bind %>% # prepare table
dplyr::select(!err) %>%
filter (Species == Sp & Month == Month_i, Day == Day_name) %>%
pivot_wider(names_from = Threshold, values_from = pred)
if(nrow(dataCOR)>0 & ncol(dataCOR)>8){
dataCOR2 = dataCOR %>%
mutate_at(vars(matches(c("0", "50", "90", "weighted"))), list(normal = f)) # normalise
# Correlation matrix
M<-cor(dataCOR2[,c("0_normal",  "50_normal",  "90_normal", "weighted_normal")])
#OVERlap = olaps(dataCOR2$'0_normal', dataCOR2$'50_normal',
#                dataCOR2$'90_normal', dataCOR2$'weighted_normal')
# Store in list
#Correlation_list_temp = list(OVERlap)
Correlation_list_temp = list(M)
names(Correlation_list_temp) = paste0(Sp, " ", Month_i, " ", Day_name)
Correlation_list = c(Correlation_list, Correlation_list_temp)
# Plot difference map
val0 = '0_normal'
val50 = '50_normal'
val90 = '90_normal'
valW = 'weighted_normal'
dataa_diff_0_50 = Raster_difference(dataCOR2, val0, val50)
dataa_diff_0_90 = Raster_difference(dataCOR2, val0, val90)
dataa_diff_0_Weighted = Raster_difference(dataCOR2, val0, valW)
dataa_diff_50_90 = Raster_difference(dataCOR2, val50, val90)
dataa_diff_50_Weighted = Raster_difference(dataCOR2, val50, valW)
dataa_diff_90_Weighted = Raster_difference(dataCOR2, val90, valW)
list_diff = list(dataa_diff_0_50, dataa_diff_0_90, dataa_diff_0_Weighted,
dataa_diff_50_90, dataa_diff_50_Weighted, dataa_diff_90_Weighted)
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
title(Sp) +
viridis::scale_fill_viridis(name = name_diff,
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
width = 10, height = 8, dpi=300)
}
}
}
}
# Calculate mean value of each correlation accross all dates
Correlation_mean = Reduce(`+`, Correlation_list) / length(Correlation_list)
Correlation_list_temp2 = list(Correlation_mean)
names(Correlation_list_temp2) = paste0(Sp)
Correlation_list2 = c(Correlation_list2, Correlation_list_temp2)
}
a
ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
title(Sp) +
viridis::scale_fill_viridis(name = name_diff,
option = "A",
na.value = alpha("lightgrey", 0))
ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp) +
viridis::scale_fill_viridis(name = name_diff,
option = "A",
na.value = alpha("lightgrey", 0))
ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
width = 10, height = 8, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
width = 1000, height = 1000, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
width = 100, height = 100, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
width = 10, height = 10, dpi=300)
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
unix = "px", width = 10, height = 8, dpi=300)
}
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
unix = "px", width = 1000, height = 800, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
units = "px", width = 1000, height = 800, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
units = "px", width = 1500, height = 1200, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
units = "px", width = 2000, height = 1700, dpi=300)
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp, " ", name_diff, ".png"),
units = "px", width = 2000, height = 1800, dpi=300)
}
Month_i
paste0(Month_i, " ", Day_name)
paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png")
DateModel="2023-11-17" #date of prediction (exactly same writing as the folder name)
paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png")
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1800, dpi=300)
}
# For each species
Correlation_list2 = list()
for (i in 1: length(ListSpdata) ) {
Sp = ListSpdata[i]
print(Sp)
# For each month
Correlation_list = list()
for (j in 1: length(ListMonthdata) ) {
# For each day
for (k in 1:2){
Month_i = ListMonthdata[j]
Day_name <- ifelse(k==1, "01", "15")
print(paste0(Month_i, " ", Day_name))
# Calculate correlations
f = function(x) {
log10(x+2) # to normalise variables to allow using pearson's correlation coefficient
}
dataCOR = file_bind %>% # prepare table
dplyr::select(!err) %>%
filter (Species == Sp & Month == Month_i, Day == Day_name) %>%
pivot_wider(names_from = Threshold, values_from = pred)
if(nrow(dataCOR)>0 & ncol(dataCOR)>8){
dataCOR2 = dataCOR %>%
mutate_at(vars(matches(c("0", "50", "90", "weighted"))), list(normal = f)) # normalise
# Correlation matrix
M<-cor(dataCOR2[,c("0_normal",  "50_normal",  "90_normal", "weighted_normal")])
#OVERlap = olaps(dataCOR2$'0_normal', dataCOR2$'50_normal',
#                dataCOR2$'90_normal', dataCOR2$'weighted_normal')
# Store in list
#Correlation_list_temp = list(OVERlap)
Correlation_list_temp = list(M)
names(Correlation_list_temp) = paste0(Sp, " ", Month_i, " ", Day_name)
Correlation_list = c(Correlation_list, Correlation_list_temp)
# Plot difference map
val0 = '0_normal'
val50 = '50_normal'
val90 = '90_normal'
valW = 'weighted_normal'
dataa_diff_0_50 = Raster_difference(dataCOR2, val0, val50)
dataa_diff_0_90 = Raster_difference(dataCOR2, val0, val90)
dataa_diff_0_Weighted = Raster_difference(dataCOR2, val0, valW)
dataa_diff_50_90 = Raster_difference(dataCOR2, val50, val90)
dataa_diff_50_Weighted = Raster_difference(dataCOR2, val50, valW)
dataa_diff_90_Weighted = Raster_difference(dataCOR2, val90, valW)
list_diff = list(dataa_diff_0_50, dataa_diff_0_90, dataa_diff_0_Weighted,
dataa_diff_50_90, dataa_diff_50_Weighted, dataa_diff_90_Weighted)
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1800, dpi=300)
}
}
}
}
# Calculate mean value of each correlation accross all dates
Correlation_mean = Reduce(`+`, Correlation_list) / length(Correlation_list)
Correlation_list_temp2 = list(Correlation_mean)
names(Correlation_list_temp2) = paste0(Sp)
Correlation_list2 = c(Correlation_list2, Correlation_list_temp2)
}
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 2000, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 1800, height = 2000, dpi=300)
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1600, dpi=300)
# For each species
Correlation_list2 = list()
for (i in 1: length(ListSpdata) ) {
Sp = ListSpdata[i]
print(Sp)
# For each month
Correlation_list = list()
for (j in 1: length(ListMonthdata) ) {
# For each day
for (k in 1:2){
Month_i = ListMonthdata[j]
Day_name <- ifelse(k==1, "01", "15")
print(paste0(Month_i, " ", Day_name))
# Calculate correlations
f = function(x) {
log10(x+2) # to normalise variables to allow using pearson's correlation coefficient
}
dataCOR = file_bind %>% # prepare table
dplyr::select(!err) %>%
filter (Species == Sp & Month == Month_i, Day == Day_name) %>%
pivot_wider(names_from = Threshold, values_from = pred)
if(nrow(dataCOR)>0 & ncol(dataCOR)>8){
dataCOR2 = dataCOR %>%
mutate_at(vars(matches(c("0", "50", "90", "weighted"))), list(normal = f)) # normalise
# Correlation matrix
M<-cor(dataCOR2[,c("0_normal",  "50_normal",  "90_normal", "weighted_normal")])
#OVERlap = olaps(dataCOR2$'0_normal', dataCOR2$'50_normal',
#                dataCOR2$'90_normal', dataCOR2$'weighted_normal')
# Store in list
#Correlation_list_temp = list(OVERlap)
Correlation_list_temp = list(M)
names(Correlation_list_temp) = paste0(Sp, " ", Month_i, " ", Day_name)
Correlation_list = c(Correlation_list, Correlation_list_temp)
# Plot difference map
val0 = '0_normal'
val50 = '50_normal'
val90 = '90_normal'
valW = 'weighted_normal'
dataa_diff_0_50 = Raster_difference(dataCOR2, val0, val50)
dataa_diff_0_90 = Raster_difference(dataCOR2, val0, val90)
dataa_diff_0_Weighted = Raster_difference(dataCOR2, val0, valW)
dataa_diff_50_90 = Raster_difference(dataCOR2, val50, val90)
dataa_diff_50_Weighted = Raster_difference(dataCOR2, val50, valW)
dataa_diff_90_Weighted = Raster_difference(dataCOR2, val90, valW)
list_diff = list(dataa_diff_0_50, dataa_diff_0_90, dataa_diff_0_Weighted,
dataa_diff_50_90, dataa_diff_50_Weighted, dataa_diff_90_Weighted)
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1600, dpi=300)
}
}
}
}
# Calculate mean value of each correlation accross all dates
Correlation_mean = Reduce(`+`, Correlation_list) / length(Correlation_list)
Correlation_list_temp2 = list(Correlation_mean)
names(Correlation_list_temp2) = paste0(Sp)
Correlation_list2 = c(Correlation_list2, Correlation_list_temp2)
}
beep(2)
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
limits = c(-1,1),
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1600, dpi=300)
# For each species
Correlation_list2 = list()
for (i in 1: length(ListSpdata) ) {
Sp = ListSpdata[i]
print(Sp)
# For each month
Correlation_list = list()
for (j in 1: length(ListMonthdata) ) {
# For each day
for (k in 1:2){
Month_i = ListMonthdata[j]
Day_name <- ifelse(k==1, "01", "15")
print(paste0(Month_i, " ", Day_name))
# Calculate correlations
f = function(x) {
log10(x+2) # to normalise variables to allow using pearson's correlation coefficient
}
dataCOR = file_bind %>% # prepare table
dplyr::select(!err) %>%
filter (Species == Sp & Month == Month_i, Day == Day_name) %>%
pivot_wider(names_from = Threshold, values_from = pred)
if(nrow(dataCOR)>0 & ncol(dataCOR)>8){
dataCOR2 = dataCOR %>%
mutate_at(vars(matches(c("0", "50", "90", "weighted"))), list(normal = f)) # normalise
# Correlation matrix
M<-cor(dataCOR2[,c("0_normal",  "50_normal",  "90_normal", "weighted_normal")])
#OVERlap = olaps(dataCOR2$'0_normal', dataCOR2$'50_normal',
#                dataCOR2$'90_normal', dataCOR2$'weighted_normal')
# Store in list
#Correlation_list_temp = list(OVERlap)
Correlation_list_temp = list(M)
names(Correlation_list_temp) = paste0(Sp, " ", Month_i, " ", Day_name)
Correlation_list = c(Correlation_list, Correlation_list_temp)
# Plot difference map
val0 = '0_normal'
val50 = '50_normal'
val90 = '90_normal'
valW = 'weighted_normal'
dataa_diff_0_50 = Raster_difference(dataCOR2, val0, val50)
dataa_diff_0_90 = Raster_difference(dataCOR2, val0, val90)
dataa_diff_0_Weighted = Raster_difference(dataCOR2, val0, valW)
dataa_diff_50_90 = Raster_difference(dataCOR2, val50, val90)
dataa_diff_50_Weighted = Raster_difference(dataCOR2, val50, valW)
dataa_diff_90_Weighted = Raster_difference(dataCOR2, val90, valW)
list_diff = list(dataa_diff_0_50, dataa_diff_0_90, dataa_diff_0_Weighted,
dataa_diff_50_90, dataa_diff_50_Weighted, dataa_diff_90_Weighted)
# For each pair of datasets
for(a in 1:length(list_diff)){
dataa_diff = as.data.frame(list_diff[a])
name_diff = paste0(sapply(strsplit(list_diff_names[a], "_"), function(x) x[3]),
" - ",
sapply(strsplit(list_diff_names[a], "_"), function(x) x[4]))
plot1 = ggplot(dataa_diff, aes(x, y, fill= z)) +
geom_tile() +
labs(title = Sp,
subtitle = paste0("Difference of predictions: ", name_diff)) +
viridis::scale_fill_viridis(name = "Bat passes per night",
option = "A",
limits = c(-1,1),
na.value = alpha("lightgrey", 0))
ggsave(plot1, filename = paste0(PredDir, "/", DateModel, "_", Sp,
"_", Month_i, "_", Day_name, "_", name_diff, ".png"),
units = "px", width = 2000, height = 1600, dpi=300)
}
}
}
}
# Calculate mean value of each correlation accross all dates
Correlation_mean = Reduce(`+`, Correlation_list) / length(Correlation_list)
Correlation_list_temp2 = list(Correlation_mean)
names(Correlation_list_temp2) = paste0(Sp)
Correlation_list2 = c(Correlation_list2, Correlation_list_temp2)
}
install.packages("pracma")
setwd("C:/Users/croemer01/Documents/R/bat-pass-duration/example files")
arg="../example files/association_buzz_species_ID/" # directory with outputs script 0_Associate_species_ID_with_buzz.R
arg[2]= "../example files/nb_buzz_per_night/" # output directory
arg[3] = "../f2pPF.R" # f2pPF function
library(tidyverse)
library(gdata)
library(data.table)
list.files(arg[1], full.names = T)
arg="../example files/species_ID/" # directory with outputs from species classifier
arg[2]="../example files/species_list.txt" # species list
arg[3]="../example files/association_buzz_species_ID"# output directory
arg[4]= "../example files/sonotype_ID" # directory with output from sonotype classifier
arg[5]=T # if T the output file will also contain buzz associated with non-bat sounds
arg[6]=0 # threshold on buzz probability of ID to filter out files with low probabilities (if 0 they are all kept)
arg[7]=0 # threshold on species probability of ID to filter out files with low probabilities (if 0 they are all kept)
list.files(arg[4], pattern = "IdTot_TOTAL")
arg="../example files/association_buzz_species_ID/" # directory with outputs script 0_Associate_species_ID_with_buzz.R
arg[2]= "../example files/nb_buzz_per_night/" # output directory
arg[3] = "../f2pPF.R" # f2pPF function
# List files
part <- list.files(arg[1], full.names = T)
m=1
buzz_id <- read.csv(part[m])
buzz_id <- buzz_id[,-1]
source(arg[3]) # Load f2pPF function
buzz_id$date <- f2pPF(buzz_id$Group.1)
buzz_id <- subset(buzz_id, buzz_id$Group=="bat")
buzz_id <- subset(buzz_id, buzz_id$probabilite>=0.5)
head(buzz_id)
start <- round_date(min(buzz_id$date), unit = "day" )- 12*3600 # take date of the beginning of the night
end <- round_date(max(buzz_id$date), unit = "day" )+ 12*3600 # take date of the end of the night
seq_date <- seq(start,end, by="day")
ListespP <- unique(buzz_id$espece)
head(buzz_id)
buzz_id$date <- f2pPF(buzz_id$Filename)
head(buzz_id)
head(f2pPF(buzz_id$Filename))
source(arg[3]) # Load f2pPF function
f2pPF(buzz_id$Filename)
buzz_id$date <- f2pPF(buzz_id$Filename)
buzz_id <- subset(buzz_id, buzz_id$Group=="bat")
buzz_id <- subset(buzz_id, buzz_id$probabilite>=0.5)
head(buzz_id)
start <- round_date(min(buzz_id$date), unit = "day" )- 12*3600 # take date of the beginning of the night
end <- round_date(max(buzz_id$date), unit = "day" )+ 12*3600 # take date of the end of the night
seq_date <- seq(start,end, by="day")
ListespP <- unique(buzz_id$espece)
compt <- 1
espBuzz=data.frame(esp = NA, nuit=NA, nb_buzz = NA)
for (i in 1:length(ListespP)) { # for each species
esp_sel=subset(buzz_id,buzz_id$espece==ListespP[i])
for (k in 2:length(seq_date)) { # for each date
esp_sel_d <- subset(esp_sel,
esp_sel$date >= seq_date[k-1] &
esp_sel$date <= seq_date[k])
espBuzz[compt,] = cbind(esp=ListespP[i], nuit = as.character(seq_date[k-1]), nb_buzz = nrow(esp_sel_d))
compt <- compt+1
}
}
head(espBuzz)
#############################
# Counts nb of buzzes per night #
#############################
# (Possible development: sort out buzzes with low confidence indexes)
arg="../example files/association_buzz_species_ID/" # directory with outputs script 0_Associate_species_ID_with_buzz.R
arg[2]= "../example files/nb_buzz_per_night/" # output directory
arg[3] = "../f2pPF.R" # f2pPF function
library(tidyverse)
library(gdata)
library(data.table)
# List files
part <- list.files(arg[1], full.names = T)
for (m in 1:length(part)) {
buzz_id <- read.csv(part[m])
buzz_id <- buzz_id[,-1]
if (!(nrow(buzz_id)==0)) {
source(arg[3]) # Load f2pPF function
buzz_id$date <- f2pPF(buzz_id$Filename)
buzz_id <- subset(buzz_id, buzz_id$Group=="bat")
buzz_id <- subset(buzz_id, buzz_id$probabilite>=0.5)
if(!(nrow(buzz_id)==0)){
start <- round_date(min(buzz_id$date), unit = "day" )- 12*3600 # take date of the beginning of the night
end <- round_date(max(buzz_id$date), unit = "day" )+ 12*3600 # take date of the end of the night
seq_date <- seq(start,end, by="day")
ListespP <- unique(buzz_id$espece)
compt <- 1
espBuzz=data.frame(esp = NA, nuit=NA, nb_buzz = NA)
for (i in 1:length(ListespP)) { # for each species
esp_sel=subset(buzz_id,buzz_id$espece==ListespP[i])
for (k in 2:length(seq_date)) { # for each date
esp_sel_d <- subset(esp_sel,
esp_sel$date >= seq_date[k-1] &
esp_sel$date <= seq_date[k])
espBuzz[compt,] = cbind(esp=ListespP[i], nuit = as.character(seq_date[k-1]), nb_buzz = nrow(esp_sel_d))
compt <- compt+1
}
}
espBuzz$nuit <- as.POSIXct(espBuzz$nuit, tz="UTC")
espBuzzfinal <- cbind(espBuzz, participation = rep(substr(part[m], 32,nchar(part[m])-4), nrow(espBuzz)))
write.csv(espBuzzfinal, file = paste0(arg[2], "NbBuzz_",substr(part[m], 32,nchar(part[i])-4),".csv"), row.names = F) }
} else {
print("pas de buzz")
}
}
part[m]
part[i]
i
part
TET = "ModRFActLog_BarbarVCweighted_2024-03-29_PGpolar.learner"
substr(TET, -13, -6)
substr(TET, -6, -13)
TET
substr(TET, nchar(TET)-13, nchar(TET)-6)
substr(TET, nchar(TET)-12, nchar(TET)-6)
substr(TET, nchar(TET)-12, nchar(TET)-7)
substr(TET, nchar(TET)-12, nchar(TET)-8)
